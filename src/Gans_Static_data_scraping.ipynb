{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7680356a-07e9-47cd-b773-c4cf98cbcbd1",
   "metadata": {},
   "source": [
    "# GANS Case study - web scraping and APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f73574-24f9-4b4e-bf98-34cdc503da5a",
   "metadata": {},
   "source": [
    "Gans is a startup developing an e-scooter-sharing system. It aspires to operate in the most populous cities all around the world. In each city, the company will have hundreds of e-scooters parked in the streets and allow users to rent them by the minute.\n",
    "\n",
    "Gans has seen that its operational success depends on something more mundane: having its scooters parked where users need them.\n",
    "Scrape information and create a database connected to SQL to hellp gather that information for GANS\n",
    "\n",
    "Step 1 - Create static databases with city and competitor information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "80bd82db-9dc8-48c7-a5ad-75df977c22a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pymysql\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "2e20eb3f-fd70-4c91-b732-1ac6c46c51e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def static_dbs_setup():\n",
    "    \"\"\"\n",
    "    This function sets up the static databases by performing the following steps:\n",
    "    1. Establishes a database connection using the connection_setup() function.\n",
    "    2. Retrieves city data and city names using the city_collection() function.\n",
    "    3. Scrapes city facts using the city_facts_scraping() function.\n",
    "    4. Calls an API to retrieve geodata using the geo_data_api_call() function.\n",
    "    5. Calls an API to retrieve airport data using the airports_api_call() function.\n",
    "    6. Scrapes competitor data for Tier and Lime using the scrape_comp_cities() function.\n",
    "    7. Performs data transformation and merging.\n",
    "    8. Sends the transformed data to SQL using various send functions.\n",
    "    9. Returns a success message.\n",
    "\n",
    "    Returns:\n",
    "    - str: A message indicating the successful upload of data.\n",
    "    \"\"\"\n",
    "    connection_string = connection_setup()\n",
    "    \n",
    "    #cities\n",
    "    city_df = city_collection()[0]\n",
    "    city_name_lst = city_collection()[1]\n",
    "    city_facts_df = city_facts_scraping(city_name_lst)\n",
    "    \n",
    "    #geodata\n",
    "    geo_data_df = geo_data_api_call(city_name_lst)\n",
    "    \n",
    "    #airports\n",
    "    latitudes = geo_data_df.latitude.to_list()\n",
    "    longitudes =geo_data_df.longitude.to_list()\n",
    "    airports_df = airports_api_call(city_name_lst, latitudes, longitudes)\n",
    "    \n",
    "#     #competitors\n",
    "    comp = {\"comp_name\":[\"Tier\", \"Rent-a-bike\",\"Lime\"],\"competitor_id\":[1,2,3]}\n",
    "    competitor_names = pd.DataFrame(data = comp)\n",
    "    url_tier = \"https://www.tier.app/en/where-to-find-us\"\n",
    "    url_lime = \"https://www.li.me/de-de/locations\"\n",
    "    tier_df = scrape_comp_cities(\"Tier\",url_tier, city_name_lst)\n",
    "    lime_df = scrape_comp_cities(\"Lime\",url_lime, city_name_lst)\n",
    "    \n",
    "    # Transformation of data\n",
    "    \n",
    "    geo_data_city_id_df = geo_data_df.merge(city_df)\n",
    "    geo_data_city_id_df = geo_data_city_id_df.drop(columns=[\"city_name\"])\n",
    "    \n",
    "    airports_city_id_df = airports_df.merge(city_df, left_on=\"city_sql\",right_on=\"city_name\")\n",
    "    airports_city_id_df = airports_city_id_df.drop(columns=[\"city_sql\",\"city_name\"])\n",
    "    \n",
    "    tier_df.insert(1,column=\"competitor_id\",value=[1]*tier_df[\"comp_city\"].count())\n",
    "    lime_df.insert(1,column=\"competitor_id\",value=[3]*lime_df[\"comp_city\"].count())\n",
    "    comp_df = pd.concat([tier_df,lime_df])\n",
    "    comp_df = comp_df.merge(city_df,how=\"inner\",left_on=\"comp_city\",right_on=\"city_name\")\n",
    "    comp_df = comp_df.drop(columns=[\"comp_city\",\"city_name\"])\n",
    "    city_df = city_df.drop(columns=[\"city_id\"])\n",
    "   \n",
    "    # Sending Data to SQL\n",
    "    send_cities(city_df,connection_string)\n",
    "    send_city_facts(city_facts_df,connection_string)\n",
    "    send_competitors(comp_df,competitor_names,connection_string)\n",
    "    send_geodata(geo_data_city_id_df,connection_string)\n",
    "    send_airports(airports_city_id_df,connection_string)\n",
    "    \n",
    "    return \"Data successfully uploaded\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65260f2-d9cd-404e-be1b-d774345fc9e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extraction\n",
    "\n",
    "Use the top 5 cities in Germany as starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2622afa1-7fe5-459e-883f-80ae4bd9c6e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "ca9525fd-5956-484f-8782-43ad944a96a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wikipedia list of top 5 cities by population\n",
    "def city_collection():\n",
    "    \"\"\"\n",
    "    Retrieves the names of cities in Germany from a Wikipedia page, removes any numeric prefixes,\n",
    "    and returns a pandas DataFrame with the first 5 city names.\n",
    "\n",
    "    Returns:\n",
    "    - city_df (pandas DataFrame): A DataFrame containing the first 5 city names in Germany.\n",
    "    \"\"\"\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_cities_in_Germany_by_population\"\n",
    "    cities_requ = requests.get(url)\n",
    "    city_soup = BeautifulSoup(cities_requ.content, \"html.parser\") \n",
    "    \n",
    "    city_names = []\n",
    "    city_id= []\n",
    "    names = []\n",
    "\n",
    "    table = city_soup.find('table', class_='sortable')\n",
    "    cities = table.find_all(class_=\"fn org\")\n",
    "    for city in cities:\n",
    "        city_names.append(city.get_text())\n",
    "\n",
    "    for city in city_names:\n",
    "        city_id.append(int(city.split(\" \",1)[0]))\n",
    "        names.append(city.split(\" \",1)[1])\n",
    "\n",
    "    city_df = pd.DataFrame(list(zip(city_id[:5],names[:5])),columns=[\"city_id\",\"city_name\"])\n",
    "    #city_df = pd.DataFrame(names[:5],columns=[\"city_name\"])\n",
    "    return city_df, names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf58494-6085-403d-93ff-18499f425f0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### city_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "d25930ca-93de-4c3c-9d19-473758e1135a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def city_facts_scraping(cities):\n",
    "    \"\"\"\n",
    "    Scrapes city facts such as country and population from Wikipedia pages for a given list of cities.\n",
    "\n",
    "    Args:\n",
    "    - cities (list): A list of city names.\n",
    "\n",
    "    Returns:\n",
    "    - results_df (pandas DataFrame): A DataFrame containing the city facts including city_id, country, and population.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {\"city_id\": [], \"country\": [], \"population\": []}\n",
    "    idx = 1\n",
    "    \n",
    "    for city in cities:\n",
    "        city_url = f\"https://en.wikipedia.org/wiki/{city}\"\n",
    "        response = requests.get(city_url)\n",
    "        city_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Write city_id into dict\n",
    "        results[\"city_id\"].append(idx)\n",
    "        \n",
    "        # Extract country and insert\n",
    "        country = city_soup.select(\"table.infobox.ib-settlement.vcard\")\n",
    "        country = country[0].find(string=\"Country\").find_next(\"td\").get_text()\n",
    "        results[\"country\"].append(country)\n",
    "\n",
    "        # extract population and insert\n",
    "        population = city_soup.select( \"table.infobox.ib-settlement.vcard\")\n",
    "        population = population[0].find(string= re.compile(r\"Population\")).find_next(\"td\").get_text()\n",
    "        population = int(re.sub(r\"(,*)\",\"\",population))\n",
    "        results[\"population\"].append(population)\n",
    "        idx +=1\n",
    "        \n",
    "    results_df = pd.DataFrame(results)\n",
    "        \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20ecec-7878-45ae-beb8-a0224d472b10",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Geodata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "055d9b25-c62d-4216-9843-c76e5cbd200c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def geo_data_api_call(city_lst):\n",
    "\n",
    "    \"\"\"\n",
    "    Scrape latitude and longitude data for a list of cities using the OpenWeatherMap API.\n",
    "\n",
    "    Args:\n",
    "        city_lst (list): A list of city names.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the scraped geo data with keys 'city', 'latitude', and 'longitude'.\n",
    "    \"\"\"\n",
    "    \n",
    "    API_key = \"91d16ed59eecaf4ad6eb1e9d19482549\"\n",
    "    country_code = \"DE\"\n",
    "    limit = 1\n",
    "    geo_data_dict = {\"city_name\": [], \"latitude\": [], \"longitude\": []}\n",
    "    for city in city_lst:\n",
    "        geo_data_dict[\"city_name\"].append(city)\n",
    "        url = f\"http://api.openweathermap.org/geo/1.0/direct?q={city},{country_code}&limit={limit}&appid={API_key}\"\n",
    "        response = requests.get(url)\n",
    "        geocode = response.json()\n",
    "        geo_data_dict[\"latitude\"].append(geocode[0].get(\"lat\",0))\n",
    "        geo_data_dict[\"longitude\"].append(geocode[0].get(\"lon\",0))\n",
    "    \n",
    "    geo_data_df = pd.DataFrame(geo_data_dict)\n",
    "    return geo_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5402a-fdea-4015-b47c-27d5580c9992",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "0e168ae4-23da-4a36-852a-b800359aae05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# API CALL \n",
    "def airports_api_call(city_names, latitudes, longitudes):\n",
    "    url = \"https://aerodatabox.p.rapidapi.com/airports/search/location\"\n",
    "    airports ={\"city_sql\":[],\"number_airports\":[],\"iata\":[],\"airport_name\":[]}\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"4b54815ac4mshe11ca88893efc1ep170ae5jsn49ac4b2d04a5\",\n",
    "        \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "    for i in range(len(city_names)):\n",
    "        querystring = {\"lat\":str(latitudes[i]),\"lon\":str(longitudes[i]),\"radiusKm\":\"50\",\"limit\":\"3\",\"withFlightInfoOnly\":\"true\"}\n",
    "        response = requests.get(url, headers=headers, params=querystring)\n",
    "        json_data = response.json()\n",
    "\n",
    "        for j in range(json_data.get(\"count\",0)):\n",
    "            airports[\"city_sql\"].append(city_names[i])\n",
    "            airports[\"number_airports\"].append(json_data.get(\"count\",0))\n",
    "            airports[\"iata\"].append(json_data[\"items\"][j].get(\"iata\",None))\n",
    "            airports[\"airport_name\"].append(json_data[\"items\"][j].get(\"name\",None))\n",
    "    airports_df = pd.DataFrame(airports)\n",
    "    return airports_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f4d8f5-61d3-48d8-9d33-268cbdf90d01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "d719a655-3f7e-40ab-bec8-efcf37b51d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_comp_cities(comp_name, url, city_name_lst):\n",
    "    \"\"\"\n",
    "    Scrapes city names from the TIER website and filters them based on a list of city names.\n",
    "    Args:\n",
    "        url (str): The URL of the TIER website.\n",
    "        city_name_lst (list): A list of city names to filter the scraped cities.\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the filtered city names from TIER.\n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If there is an error in making the HTTP request.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        # Get the data from TIER website\n",
    "        response_comp = requests.get(url)\n",
    "        comp_soup = BeautifulSoup(response_comp.content, \"html.parser\")\n",
    "        \n",
    "        if  comp_name == \"Tier\":\n",
    "            # Scrape city names from TIER\n",
    "            city_elements = comp_soup.select('.KPICard__Card-sc-1wpi9bh-0 p')\n",
    "            comp_cities = [element.text.strip() for element in city_elements]\n",
    "        elif comp_name == \"Lime\":\n",
    "            comp_cities = []\n",
    "            lime_cities = comp_soup.find_all(\"div\", class_= \"inline-block mb-1 w-full text-xs text-gray-300 md:mb-4 md:text-lg md:border-gray-300 md:border-opacity-40\")\n",
    "            for item in lime_cities:\n",
    "                city =item.get_text().strip().replace('\\n', '')\n",
    "                comp_cities.append(city)\n",
    "                \n",
    "        # Filter cities that are also in the city_name_lst\n",
    "        comp_cities_lst = [comp_city for comp_city in comp_cities if comp_city in city_name_lst]\n",
    "\n",
    "        # Create a DataFrame with the filtered city names\n",
    "        comp_cities_df = pd.DataFrame(comp_cities_lst, columns=[\"comp_city\"])\n",
    "\n",
    "        return comp_cities_df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle any request exceptions\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6fbab6-d6ac-47d8-9db7-a86550eac1b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57077e1-1978-4838-9f06-1e80e3a9f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_setup():\n",
    "    \"\"\"\n",
    "    Sets up the connection string for connecting to a MySQL database.\n",
    "    Returns:\n",
    "    - connection_string (str): The connection string for connecting to the MySQL database.\n",
    "    \"\"\"\n",
    "    schema = \"gans_locations\"\n",
    "    host = \"host\"\n",
    "    user = \"root\"\n",
    "    password = os.environ.get(\"Password\")\n",
    "    port = 3306\n",
    "    connection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "    return connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "d48a6958-2f72-41d7-ad13-6f62b686797c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def send_cities(city_df,connection_string):\n",
    "    \"\"\"\n",
    "    Writes the city names from a pandas DataFrame to a MySQL database table. Replaces - existing Values\n",
    "    Args:\n",
    "    - city_df (pandas DataFrame): The DataFrame containing the city names.\n",
    "    - connection_string (str): The connection string for connecting to the MySQL database.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    city_df.to_sql('cities',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "b72f63ab-ab78-4928-827b-376d89fe6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_city_facts(city_facts_df,connection_string):\n",
    "    \"\"\"\n",
    "    Writes the city facts from a pandas DataFrame to a MySQL database table. Replaces - existing Values\n",
    "    Args:\n",
    "    - city_fact_df (pandas DataFrame): The DataFrame containing the city facts scraped before\n",
    "    - connection_string (str): The connection string for connecting to the MySQL database.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    city_facts_df.to_sql('city_facts',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "8565eb67-1653-4455-b007-e91613f90c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_competitors(comp_df,competitor_names,connection_string):\n",
    "    \"\"\"\n",
    "    Writes the competitor_names and Ids  from a pandas DataFrame to a MySQL database table. Replaces - existing Values\n",
    "    Secondly writes a dataframe wit competitor cities to a database table\n",
    "    Args:\n",
    "    - comp_df: the list of cities per competitor\n",
    "    - competitor names: assigns an Id per competitor name\n",
    "    -connection_string: String to connect with MYSQL\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    competitor_names.to_sql('competitors',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)\n",
    "\n",
    "\n",
    "\n",
    "    comp_df.to_sql('comp_cities',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "02398899-6d15-4b53-88d5-37a28401fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_geodata(geo_data,connection_string):\n",
    "    \"\"\"\n",
    "    Writes the  geodata for each city from a pandas DataFrame to a MySQL database table. Replaces - existing Values\n",
    "    Args:\n",
    "    - geo_data (pandas DataFrame): The DataFrame containing the latitudes and longitudes scraped before\n",
    "    - connection_string (str): The connection string for connecting to the MySQL database.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    geo_data.to_sql('geo_data',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "2acae2cf-a3ba-4ca5-bdb9-8e99174dee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_airports(airports,connection_string):\n",
    "    \"\"\"\n",
    "    Writes the airports data for each city from a pandas DataFrame to a MySQL database table. Replaces - existing Values\n",
    "    Args:\n",
    "    - airports (pandas DataFrame): The DataFrame containing the airports short form scraped before\n",
    "    - connection_string (str): The connection string for connecting to the MySQL database.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    airports.to_sql('airports',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f742394-7292-4ac4-adc9-1133b0c4352d",
   "metadata": {},
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "0646f56e-4050-4eee-91e4-705cc54a67d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data successfully uploaded'"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_dbs_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "b367a4d1-3f35-45ec-a907-2d6ba742d753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_airports</th>\n",
       "      <th>iata</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>city_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BER</td>\n",
       "      <td>Berlin Brandenburg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MUC</td>\n",
       "      <td>Munich</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CGN</td>\n",
       "      <td>Cologne Bonn</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Frankfurt-am-Main</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_airports iata        airport_name  city_id\n",
       "0                1  BER  Berlin Brandenburg        1\n",
       "1                1  HAM            Hamburg         2\n",
       "2                1  MUC             Munich         3\n",
       "3                1  CGN        Cologne Bonn        4\n",
       "4                1  FRA  Frankfurt-am-Main         5"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"airports\", con=connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30510e61-c95c-457d-8e1b-2fea191dce5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
